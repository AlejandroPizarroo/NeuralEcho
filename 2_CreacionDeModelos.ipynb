{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Creación de Modelos\n",
        "\n",
        "<h3> Creación de modelos en base a máscaras y a puntos de interés\n",
        "\n",
        "Equipo de Reto 5\n",
        "\n",
        "Inteligencia artificial avanzada para la ciencia de datos II (Grupo 502)\n",
        "\n",
        "30 de noviembre de 2023"
      ],
      "metadata": {
        "id": "3KMh7VjQf6WM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparar el entorno de trabajo"
      ],
      "metadata": {
        "id": "UKZZq8tEhVi5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzsB6USHfzcI"
      },
      "outputs": [],
      "source": [
        "# Importar librerias y módulos necesarios\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Activation, MaxPooling2D, Conv2DTranspose, Concatenate, Input\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from keras.models import load_model\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el directorio de trabajo actual\n",
        "os.chdir('/content/drive/Shareddrives/Penta Tech/Reto')"
      ],
      "metadata": {
        "id": "6RjnuTfbhkvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el directorio con los conjuntos de datos\n",
        "data_directory = os.path.join(os.getcwd(), 'CompleteDatasets')"
      ],
      "metadata": {
        "id": "MUWjCH_qhsxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el directorio para guardar los mejores modelos y su historial de entrenamiento\n",
        "models_directory = os.path.join(os.getcwd(), 'Models')\n",
        "os.mkdir(models_directory)\n",
        "logs_directory = os.path.join(os.getcwd(), 'Logs')\n",
        "os.mkdir(logs_directory)"
      ],
      "metadata": {
        "id": "SDPxR_WiblVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir dimensiones importantes de los datos\n",
        "img_height = 112\n",
        "img_width = 112\n",
        "img_channels = 1\n",
        "mask_channels = 1\n",
        "landmarks_channels = 7"
      ],
      "metadata": {
        "id": "gFnkG1m-llot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir la arquitectura para un modelo U-Net"
      ],
      "metadata": {
        "id": "LaKUAYE0itph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir un bloque convolucional\n",
        "def conv_block(input, num_filters):\n",
        "  x = Conv2D(num_filters, 3, padding='same')(input)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(num_filters, 3, padding='same')(x)\n",
        "  x = Activation('relu')(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "NhRyeheaizBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir un bloque codificador\n",
        "def encoder_block(input, num_filters):\n",
        "  x = conv_block(input, num_filters)\n",
        "  p = MaxPooling2D((2,2))(x)\n",
        "  return x, p"
      ],
      "metadata": {
        "id": "M3DSTaKWjCVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir un bloque decodificador\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "  x = Conv2DTranspose(num_filters, (2,2), strides=2, padding='same')(input)\n",
        "  x = Concatenate()([x, skip_features])\n",
        "  x = conv_block(x, num_filters)\n",
        "  return x"
      ],
      "metadata": {
        "id": "z8BksLd6jSnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la arquitectura para un modelo U-Net\n",
        "def build_unet(input_shape, num_clases):\n",
        "  inputs = Input(input_shape)\n",
        "\n",
        "  s1, p1 = encoder_block(inputs, 64)\n",
        "  s2, p2 = encoder_block(p1, 128)\n",
        "  s3, p3 = encoder_block(p2, 256)\n",
        "  s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "  b1 = conv_block(p4, 1024)\n",
        "\n",
        "  d1 = decoder_block(b1, s4, 512)\n",
        "  d2 = decoder_block(d1, s3, 256)\n",
        "  d3 = decoder_block(d2, s2, 128)\n",
        "  d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "  outputs = Conv2D(num_clases, 1, padding='same', activation='sigmoid')(d4)\n",
        "\n",
        "  model = Model(inputs, outputs, name='U-Net')\n",
        "  return model"
      ],
      "metadata": {
        "id": "WxClJRFKjehy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crear y entrenar un modelo U-Net basado en máscaras"
      ],
      "metadata": {
        "id": "6l0mHvZYlMCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de entrenamiento\n",
        "train_input = np.load(os.path.join(data_directory, 'train_images.npy'))\n",
        "train_output = np.load(os.path.join(data_directory, 'train_masks.npy'))\n",
        "print('Dimensiones del conjunto de entrenamiento:', train_input.shape, train_output.shape)\n",
        "\n",
        "# Cargar el conjunto de validación\n",
        "val_input = np.load(os.path.join(data_directory, 'val_images.npy'))\n",
        "val_output = np.load(os.path.join(data_directory, 'val_masks.npy'))\n",
        "print('Dimensiones del conjunto de validación   :', val_input.shape, val_output.shape)"
      ],
      "metadata": {
        "id": "vSlyk6n1asGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y compilar el modelo basado en máscaras\n",
        "mask_model = build_unet((img_height, img_height, img_channels), mask_channels)\n",
        "mask_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "eTJV6x2slQQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir \"Callbacks\" para guardar los modelos mejor entrenados y el historial de entrenamiento\n",
        "checkpoint = ModelCheckpoint(os.path.join(models_directory, 'masks_{epoch:02d}_{val_accuracy:.2f}.h5'), monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "log_csv = CSVLogger(os.path.join(logs_directory, 'MaskModels.csv'), separator=',', append=False)"
      ],
      "metadata": {
        "id": "3CZx1xjBmVEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo con los datos de entrenamiento y validación\n",
        "mask_model.fit(train_input, train_output,\n",
        "               validation_data=(val_input, val_output),\n",
        "               batch_size = 64,\n",
        "               callbacks=[checkpoint, log_csv],\n",
        "               epochs=10)"
      ],
      "metadata": {
        "id": "NzDqDxEVmdLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crear y entrenar un modelo U-Net basado en puntos de interés"
      ],
      "metadata": {
        "id": "LCelMm14lQry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de entrenamiento\n",
        "train_input = np.load(os.path.join(data_directory, 'train_images.npy'))\n",
        "train_output = np.load(os.path.join(data_directory, 'train_landmarks.npy'))\n",
        "print('Dimensiones del conjunto de entrenamiento:', train_input.shape, train_output.shape)\n",
        "\n",
        "# Cargar el conjunto de validación\n",
        "val_input = np.load(os.path.join(data_directory, 'val_images.npy'))\n",
        "val_output = np.load(os.path.join(data_directory, 'val_landmarks.npy'))\n",
        "print('Dimensiones del conjunto de validación:   ', val_input.shape, val_output.shape)"
      ],
      "metadata": {
        "id": "ppIruJEobCB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y compilar el modelo basado en puntos de interés\n",
        "landmark_model = build_unet((img_height, img_height, img_channels), landmarks_channels)\n",
        "landmark_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uhHvTLpQk9DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir \"Callbacks\" para guardar los modelos mejor entrenados y el historial de entrenamiento\n",
        "checkpoint = ModelCheckpoint(os.path.join(models_directory, 'landmarks_{epoch:02d}_{val_accuracy:.2f}.h5'), monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "log_csv = CSVLogger(os.path.join(logs_directory, 'LandmarkModels.csv'), separator=',', append=False)"
      ],
      "metadata": {
        "id": "z7FOaoPu5W9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo con los datos de entrenamiento y validación\n",
        "landmark_model.fit(train_input, train_output,\n",
        "               validation_data=(val_input, val_output),\n",
        "               batch_size = 64,\n",
        "               callbacks=[checkpoint, log_csv],\n",
        "               epochs=10)"
      ],
      "metadata": {
        "id": "LolH1k-2nkGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probar el funcionamiento de los mejores modelos con el conjunto de prueba"
      ],
      "metadata": {
        "id": "L6aC7z-Mnzev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrar los conjuntos de entrenamiento y validación tras entrenar los modelos\n",
        "train_input = train_output = val_input = val_output = 0\n",
        "\n",
        "# Cargar el conjunto de prueba\n",
        "test_images = np.load(os.path.join(data_directory, 'test_images.npy'))\n",
        "print('Dimensiones del conjunto de prueba:', test_images.shape)"
      ],
      "metadata": {
        "id": "2MPEirNPdqcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los mejores modelos\n",
        "mask_model = load_model(os.path.join(models_directory, 'masks_08_0.99.h5'), compile=False)\n",
        "landmark_model = load_model(os.path.join(models_directory, 'landmarks_05_0.45.h5'), compile=False)"
      ],
      "metadata": {
        "id": "bq0i1n7SBUW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con ambos modelos todos los datos en el conjunto de prueba\n",
        "mask_predictions = mask_model.predict(test_images)\n",
        "landmark_predictions = landmark_model.predict(test_images)"
      ],
      "metadata": {
        "id": "h6oiEjD78ap2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar predicciones para datos aleatorios del conjunto de prueba\n",
        "predictions = []\n",
        "\n",
        "# Para k número de predicciones\n",
        "for index in random.choices(range(0, len(test_images)), k=5):\n",
        "\n",
        "  # Seleccionar la imagen original y convertir a tres canales\n",
        "  frame = test_images[index]\n",
        "  frame = np.concatenate([frame, frame, frame], axis=2)\n",
        "\n",
        "  # Añadir la máscara sobre la imagen original\n",
        "  mask_prediction = np.squeeze(mask_predictions[index] > 0.5)\n",
        "  frame[:,:,0] = cv2.addWeighted(mask_prediction.astype(np.float32), 0.75, frame[:,:,0].astype(np.float32), 1, 0)\n",
        "\n",
        "  # Añadir los puntos de interés sobre la imagen original\n",
        "  landmarks_prediction = landmark_predictions[index]\n",
        "  background = np.zeros_like(frame[:,:,0])\n",
        "  for channel in range(landmarks_prediction.shape[2]):\n",
        "    landmark = (landmarks_prediction[:,:,channel] >= np.max(landmarks_prediction[:,:,channel]))\n",
        "    coord = np.unravel_index(np.argmax(landmark), landmark.shape)\n",
        "    coord = (coord[1], coord[0])\n",
        "    cv2.circle(background, coord, 2, 255, -1)\n",
        "  frame[:,:,2] = cv2.addWeighted(background.astype(np.float32), 0.75, frame[:,:,2].astype(np.float32), 1, 0)\n",
        "\n",
        "  # Añadir la imagen a una lista\n",
        "  predictions.append(frame * 255)\n",
        "\n",
        "# Mostrar en una sola línea las imagenes originales con sus predicciones\n",
        "divider = np.full((img_height, 1, 3), 255)\n",
        "cv2_imshow(np.concatenate((predictions[0], divider, predictions[1], divider, predictions[2], divider, predictions[3], divider, predictions[4]), axis=1))"
      ],
      "metadata": {
        "id": "Fdg-IxmciW_G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}