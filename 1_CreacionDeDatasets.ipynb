{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcLpBy1whxGN"
      },
      "source": [
        "<h1> Creación de Datasets\n",
        "\n",
        "<h3> Creación de arreglos de NumPy para almacenar los datos de entrenamiento, validación y prueba de ambos modelos\n",
        "\n",
        "Equipo de Reto 5\n",
        "\n",
        "Inteligencia artificial avanzada para la ciencia de datos II (Grupo 502)\n",
        "\n",
        "30 de noviembre de 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eumaHlZpjvuD"
      },
      "source": [
        "### Preparar el entorno de trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mf8KLOpjvK5"
      },
      "outputs": [],
      "source": [
        "# Importar librerias y módulos necesarios\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from scipy.spatial import ConvexHull\n",
        "import numpy as np\n",
        "import sys\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc5rXn2sSWm0"
      },
      "outputs": [],
      "source": [
        "# Definir el directorio de trabajo actual\n",
        "os.chdir('/content/drive/Shareddrives/Penta Tech/Reto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH7_U27WKUIp"
      },
      "outputs": [],
      "source": [
        "# Definir dimensiones importantes de los datos\n",
        "img_height = 112\n",
        "img_width = 112\n",
        "img_channels = 1\n",
        "mask_channels = 1\n",
        "landmarks_channels = 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P95c-UmVj9F0"
      },
      "source": [
        "### Cargar la lista de archivos y de trazos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfALahHjqAIC"
      },
      "outputs": [],
      "source": [
        "# Lista de archivos\n",
        "file_list = pd.read_csv(os.path.join(os.getcwd(), 'EchoNet-Dynamic/FileList.csv'))\n",
        "file_list.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n7LnAlthgMr"
      },
      "outputs": [],
      "source": [
        "# Lista de trazos\n",
        "volume_tracings = pd.read_csv(os.path.join(os.getcwd(), 'EchoNet-Dynamic/VolumeTracings.csv'))\n",
        "volume_tracings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KloY4BBWqc1u"
      },
      "outputs": [],
      "source": [
        "# Identificar todos los fotogramas trazados\n",
        "labeled_frames = volume_tracings.groupby(['FileName', 'Frame']).size().reset_index(name='Count')\n",
        "labeled_frames.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrar del listado los fotogramas de videos que no existen o producen errores\n",
        "labeled_frames.drop([7761, 8772, 10670, 10671, 11325, 12282, 12509, 18963, 19239, 19699], inplace=True)"
      ],
      "metadata": {
        "id": "EHI5ujiBtQhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qwQhx2wKZss"
      },
      "source": [
        "### Crear arreglos para almacenar los datos de entrenamiento, validación y prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMREK-TFJiRX"
      },
      "outputs": [],
      "source": [
        "# Conjunto de entrenamiento\n",
        "train_images = np.empty((0, img_height, img_width, img_channels), dtype=np.float16)\n",
        "train_masks = np.empty((0, img_height, img_width, mask_channels), dtype=np.float16)\n",
        "train_landmarks = np.empty((0, img_height, img_width, landmarks_channels), dtype=np.float16)\n",
        "\n",
        "# Conjunto de validación\n",
        "val_images = np.empty((0, img_height, img_width, img_channels), dtype=np.float16)\n",
        "val_masks = np.empty((0, img_height, img_width, mask_channels), dtype=np.float16)\n",
        "val_landmarks = np.empty((0, img_height, img_width, landmarks_channels), dtype=np.float16)\n",
        "\n",
        "# Conjunto de prueba\n",
        "test_images = np.empty((0, img_height, img_width, img_channels), dtype=np.float16)\n",
        "test_masks = np.empty((0, img_height, img_width, mask_channels), dtype=np.float16)\n",
        "test_landmarks = np.empty((0, img_height, img_width, landmarks_channels), dtype=np.float16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySNFST9BJoHx"
      },
      "source": [
        "### Dividir y guardar los datos de los conjuntos de entrenamiento, validación y prueba"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPCIONAL: Seleccionar un rango de datos\n",
        "labeled_frames = labeled_frames.iloc[3*(labeled_frames.shape[0]//4):]"
      ],
      "metadata": {
        "id": "srySpVv0zes2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9LtAUZ5rCQ7"
      },
      "outputs": [],
      "source": [
        "# Para todos los fotogramas trazados\n",
        "for index, series in labeled_frames.iterrows():\n",
        "\n",
        "  # Abrir el fotograma\n",
        "  videos_path = os.path.join(os.getcwd(), 'EchoNet-Dynamic/Videos', series[0])\n",
        "  cap = cv2.VideoCapture(videos_path)\n",
        "  cap.set(cv2.CAP_PROP_POS_FRAMES, series[1])\n",
        "  _, frame = cap.read()\n",
        "  cap.release()\n",
        "\n",
        "  # Ordenar los puntos del trazo utilizando el algoritmo Convex Hull\n",
        "  points = volume_tracings[(volume_tracings['FileName'] == series[0]) & (volume_tracings['Frame'] == series[1])]\n",
        "  c_h_points = pd.DataFrame({'X': pd.concat([points.X1, points.X2], ignore_index=True), 'Y': pd.concat([points.Y1, points.Y2], ignore_index=True)})\n",
        "  c_h_points = c_h_points.iloc[ConvexHull(c_h_points[['X', 'Y']].values).vertices]\n",
        "\n",
        "  # Crear una máscara del fotograma\n",
        "  h, w, _ = frame.shape\n",
        "  background = np.zeros((frame.shape[0], frame.shape[1], mask_channels)).astype(np.uint8)\n",
        "  mask = np.array(c_h_points.values.astype(np.int32)).reshape((-1, 1, 2))\n",
        "  cv2.fillPoly(background, [mask], 255)\n",
        "\n",
        "  # Almacenar las pendientes y puntos de las líneas trazadas\n",
        "  slopes, left, right = [], [], []\n",
        "  for _, line in points.iterrows():\n",
        "    if line['X2'] == line['X1']:\n",
        "      slopes.append(sys.maxsize)\n",
        "      left.append((line['X1'], line['Y1']))\n",
        "      right.append((line['X2'], line['Y2']))\n",
        "    elif line['X2'] > line['X1']:\n",
        "      slopes.append((line['Y2'] - line['Y1']) / (line['X2'] - line['X1']))\n",
        "      left.append((line['X1'], line['Y1']))\n",
        "      right.append((line['X2'], line['Y2']))\n",
        "    else:\n",
        "      slopes.append((line['Y1'] - line['Y2']) / (line['X1'] - line['X2']))\n",
        "      left.append((line['X2'], line['Y2']))\n",
        "      right.append((line['X1'], line['Y1']))\n",
        "\n",
        "  # Identificar la única línea vertical trazada\n",
        "  if abs(max(slopes) - np.mean(slopes)) > abs(min(slopes) - np.mean(slopes)):\n",
        "    a_index = slopes.index(max(slopes))\n",
        "  else:\n",
        "    a_index = slopes.index(min(slopes))\n",
        "\n",
        "  # Guardar la coordenada del punto más alto del trazo\n",
        "  coords = []\n",
        "  apex = points.iloc[a_index]\n",
        "  if apex['Y2'] < apex['Y1']:\n",
        "    coords.append((apex['X2'], apex['Y2']))\n",
        "  else:\n",
        "    coords.append((apex['X1'], apex['Y1']))\n",
        "\n",
        "  # Guardar la coordenada de los puntos más bajos del trazo\n",
        "  max_area = 0\n",
        "  for l in left:\n",
        "    for r in right:\n",
        "      area = 0.5 * abs(coords[0][0] * (l[1] - r[1]) + l[0] * (r[1] - coords[0][1]) + r[0] * (coords[0][1] - l[1]))\n",
        "      if area >= max_area:\n",
        "        max_area = area\n",
        "        bases = (l, r)\n",
        "  coords.append(bases[0])\n",
        "  coords.append(bases[1])\n",
        "\n",
        "  # Identificar los puntos intermedios en cada lado\n",
        "  left = sorted(left, key=lambda l: l[1])\n",
        "  right = sorted(right, key=lambda r: r[1])\n",
        "  left = left[:left.index(coords[1])]\n",
        "  right = right[:right.index(coords[2])]\n",
        "  coords.append(left[len(left)//3])\n",
        "  coords.append(right[len(right)//3])\n",
        "  coords.append(left[2*len(left)//3])\n",
        "  coords.append(right[2*len(right)//3])\n",
        "\n",
        "  # Crear un arreglo con los puntos más importantes\n",
        "  landmarks = np.zeros((frame.shape[0], frame.shape[1], len(coords)), dtype=np.uint8)\n",
        "  for coord in coords:\n",
        "    channel_image = np.zeros((frame.shape[:2]))\n",
        "    cv2.circle(channel_image, (int(coord[0]), int(coord[1])), 4, 255, -1)\n",
        "    channel_image = gaussian_filter(channel_image, sigma=2)\n",
        "    landmarks[:,:,coords.index(coord)] = channel_image\n",
        "\n",
        "  # Guardar el fotograma, la máscara y los puntos más importantes en los arreglos correspondientes\n",
        "  split = file_list.loc[file_list['FileName'] == series[0][:-4], 'Split'].iloc[0]\n",
        "  greyscale_frame = np.expand_dims(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), axis=-1).astype(np.uint8)\n",
        "  if split == 'TRAIN':\n",
        "      train_images = np.append(train_images.astype(np.float16), [(greyscale_frame/255.0).astype(np.float16)], axis=0)\n",
        "      train_masks = np.append(train_masks.astype(np.float16), [(mask/255.0).astype(np.float16)], axis=0)\n",
        "      train_landmarks = np.append(train_landmarks.astype(np.float16), [(landmarks/255.0).astype(np.float16)], axis=0)\n",
        "  if split == 'VAL':\n",
        "      val_images = np.append(val_images.astype(np.float16), [(greyscale_frame/255.0).astype(np.float16)], axis=0)\n",
        "      val_masks = np.append(val_masks.astype(np.float16), [(mask/255.0).astype(np.float16)], axis=0)\n",
        "      val_landmarks = np.append(val_landmarks.astype(np.float16), [(landmarks/255.0).astype(np.float16)], axis=0)\n",
        "  if split == 'TEST':\n",
        "      test_images = np.append(test_images.astype(np.float16), [(greyscale_frame/255.0).astype(np.float16)], axis=0)\n",
        "      test_masks = np.append(test_masks.astype(np.float16), [(mask/255.0).astype(np.float16)], axis=0)\n",
        "      test_landmarks = np.append(test_landmarks.astype(np.float16), [(landmarks/255.0).astype(np.float16)], axis=0)\n",
        "\n",
        "  # Imprimir la información de los datos\n",
        "  print(f'ÍNDICE: {index}  VIDEO: {series[0]}  FOTOGRAMA: {series[1]}  CONJUNTO: {split}')\n",
        "\n",
        "  # Mostrar el fotograma, la máscara, los puntos más importantes y las líneas del trazo\n",
        "  # frame[:,:,0] = cv2.addWeighted(mask.astype(np.uint8), 0.75, frame[:,:,0], 1, 0)\n",
        "  # for coord in coords:\n",
        "  #   cv2.circle(frame, (int(coord[0]), int(coord[1])), 1, (0, 0, 255), -1)\n",
        "  # for _, point in points.iterrows():\n",
        "  #   cv2.line(frame, (int(point.X1), int(point.Y1)), (int(point.X2), int(point.Y2)), (0, 255, 0), thickness=1)\n",
        "  # cv2_imshow(frame)\n",
        "\n",
        "# Crear directorio para guardar todos los arreglos como archivos\n",
        "array_directory = os.path.join(os.getcwd(), 'Datasets')\n",
        "os.mkdir(array_directory)\n",
        "\n",
        "# Guardar todos los arreglos de entrenamiento\n",
        "np.save(os.path.join(array_directory, 'train_images.npy'), train_images.astype(np.float16))\n",
        "np.save(os.path.join(array_directory, 'train_masks.npy'), train_masks.astype(np.float16))\n",
        "np.save(os.path.join(array_directory, 'train_landmarks.npy'), train_landmarks.astype(np.float16))\n",
        "\n",
        "# Guardar todos los arreglos de validación\n",
        "np.save(os.path.join(array_directory, 'val_images.npy'), val_images.astype(np.float16))\n",
        "np.save(os.path.join(array_directory, 'val_masks.npy'), val_masks.astype(np.float16))\n",
        "np.save(os.path.join(array_directory, 'val_landmarks.npy'), val_landmarks.astype(np.float16))\n",
        "\n",
        "# Guardar todos los arreglos de prueba\n",
        "np.save(os.path.join(array_directory, 'test_images.npy'), test_images.astype(np.float16))\n",
        "np.save(os.path.join(array_directory, 'test_masks.npy'), test_masks.astype(np.float16))\n",
        "np.save(os.path.join(array_directory, 'test_landmarks.npy'), test_landmarks.astype(np.float16))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV6moNiLU2E-"
      },
      "source": [
        "### Validar que los arreglos se hayan guardado correctamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vBuj70RPBlg"
      },
      "outputs": [],
      "source": [
        "# Imprimir las dimensiones de los archivos de entrenamiento\n",
        "print('Imágenes de entrenamiento:', np.load(os.path.join(array_directory, 'train_images.npy')).shape)\n",
        "print('Máscaras de entrenamiento:', np.load(os.path.join(array_directory, 'train_masks.npy')).shape)\n",
        "print('Puntos de entrenamiento:  ', np.load(os.path.join(array_directory, 'train_landmarks.npy')).shape, '\\n')\n",
        "\n",
        "# Imprimir las dimensiones de los archvios de validación\n",
        "print('Imágenes de validación:   ', np.load(os.path.join(array_directory, 'val_images.npy')).shape)\n",
        "print('Máscaras de validación:   ', np.load(os.path.join(array_directory, 'val_masks.npy')).shape)\n",
        "print('Puntos de validación:     ', np.load(os.path.join(array_directory, 'val_landmarks.npy')).shape, '\\n')\n",
        "\n",
        "# Imprimir las dimensiones de los archivos de prueba\n",
        "print('Imágenes de prueba:       ', np.load(os.path.join(array_directory, 'test_images.npy')).shape)\n",
        "print('Máscaras de prueba:       ', np.load(os.path.join(array_directory, 'test_masks.npy')).shape)\n",
        "print('Puntos de prueba:         ', np.load(os.path.join(array_directory, 'test_landmarks.npy')).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OPCIONAL: Concatenar los nuevos arreglos a aquellos previamente almacenados\n",
        "\n"
      ],
      "metadata": {
        "id": "kmww1ZFCfy8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el directorio con los archivos generados anteriormente\n",
        "complete_array_directory = os.path.join(os.getcwd(), 'CompleteDatasets')\n",
        "\n",
        "# Añadir los nuevos datos a los conjuntos existentes\n",
        "for file in os.listdir(complete_array_directory):\n",
        "  array = np.load(os.path.join(array_directory, file))\n",
        "  complete_array = np.load(os.path.join(complete_array_directory, file))\n",
        "  complete_array = np.concatenate((array, complete_array), axis=0)\n",
        "  np.save(os.path.join(complete_array_directory, file), complete_array)\n",
        "  print(f'El archivo {file} se actualizó con éxito')\n",
        "  print(f'  Dimensiones: {complete_array.shape}  Tipo: {complete_array.dtype}')"
      ],
      "metadata": {
        "id": "8Ta-1kD-iw9j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}